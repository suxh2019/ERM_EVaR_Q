
## Reused the code from the previous paper
We reuse the code of linear program from the previous paper. We include the authors' name, paper title, the link to the code of the paper and the instructions to run the code here.
    Xihong Su, Marek Petrik, Julien Grand-Cl√©ment. Risk-averse Total-reward MDPs with ERM and EVaR. The 39th Annual AAAI Conference on Artificial Intelligence(AAAI2025). The link to the code
    is https://github.com/suxh2019/ERMLP .

   In order to run the code, please install MDPs and RiskMDPs packages at https://github.com/RiskAverseRL/RiskMDPs.jl

## Preliminary
(1) Install Julia and VSCode.
(2) Open VSCode and then open the folder linear_program

## File Structure
- linear_program
    - cliff.csv: CSV file containing domain transition and reward on cliff walking(CW) domain
    - gambler.csv:  CSV file containing domain transition and reward on gambler ruin(GR) domain
    - LP_cliff.jl: calculate the EVaR value computed by the linear program on CW domain
    - LP_gambler.jl: calculate the EVaR value computed by the linear program on GR domain
    - mean-std.jl: plot the mean value and standard deviation values for EVaR values computed by
                   Q-learning algorithm for samples generated by six random seeds on CW domain.
    - simulate_returns.jl: plot the distribution of returns of two EVaR optimal policy computed by
                   Q-learning on CW domain.


- figures/
   - figure 1/:  q_cliff_0.2.jl
   - figure 2/: q_cliff_0.6.jl
   - figure 3/: q_cliff_0.2.jl ,q_cliff_0.6.jl,simulate_returns.jl
   - figure 4/:  mean_std_cliff_0.2.jl,mean-std.jl
   - figure 5/:  plot_lp_q_cliff.jl,  q_cliff_multiple.jl ,LP_cliff.jl
   - figure 6/:   plot_lp_q_gambler.jl, q_gambler_0.2.jl,  LP_gambler.jl